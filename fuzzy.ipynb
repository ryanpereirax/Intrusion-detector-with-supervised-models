{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGFhQ0frmiJVUSyhmMKXgD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanpereirax/Intrusion-detector-with-supervised-models/blob/main/fuzzy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmXYxE27601T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GjRPJtkx0JwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzy_df = pd.read_csv('/content/Fuzzy_dataset.csv')\n"
      ],
      "metadata": {
        "id": "LrPgYG8MzBub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amostras de 1% do Dataset Original\n",
        "amostras_R = fuzzy_df[fuzzy_df['R'] == 'R'].sample(n=5_000, random_state=42)\n",
        "amostras_T = fuzzy_df[fuzzy_df['R'] == 'T'].sample(n=4_000, random_state=42)\n",
        "fuzzy_df_balanceado = pd.concat([amostras_R, amostras_T]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "fuzzy_df_balanceado.to_csv('fuzzy_df_proporcional_ajustado.csv', index=False)"
      ],
      "metadata": {
        "id": "qfEawR5yzEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVjFKk3Lwq7K",
        "outputId": "49e5c791-6c5b-439b-bfa8-3d7c16a2924d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QFiFcb8wwpz",
        "outputId": "b3199eac-7c2c-4d15-ec4e-4063d43732f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphviz, catboost\n",
            "Successfully installed catboost-1.2.7 graphviz-0.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kvnxvFxsaLZL",
        "outputId": "9ecd1920-3824-40e3-a264-d8ab01c32bb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1478195721.903877  0545  8  d8  00 00.1  8a 00.2 00.3 00.4 00.5  R\n",
              "0       1.478196e+09  05f4  8  29  17   cf  bf   be   3c   2a   dd  T\n",
              "1       1.478198e+09  0130  8  0f  80   00  ff   22   80   06   e4  R\n",
              "2       1.478198e+09  0316  8  05  22   7c  09   22   21   00   6f  R\n",
              "3       1.478201e+09  04f0  8  00  00   00  80   00   69   d1   13  R\n",
              "4       1.478198e+09  0359  8  ed  28   fa  f5   34   e3   17   bd  T"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37e88421-cd76-42ae-b818-8e9b020de728\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1478195721.903877</th>\n",
              "      <th>0545</th>\n",
              "      <th>8</th>\n",
              "      <th>d8</th>\n",
              "      <th>00</th>\n",
              "      <th>00.1</th>\n",
              "      <th>8a</th>\n",
              "      <th>00.2</th>\n",
              "      <th>00.3</th>\n",
              "      <th>00.4</th>\n",
              "      <th>00.5</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.478196e+09</td>\n",
              "      <td>05f4</td>\n",
              "      <td>8</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>cf</td>\n",
              "      <td>bf</td>\n",
              "      <td>be</td>\n",
              "      <td>3c</td>\n",
              "      <td>2a</td>\n",
              "      <td>dd</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.478198e+09</td>\n",
              "      <td>0130</td>\n",
              "      <td>8</td>\n",
              "      <td>0f</td>\n",
              "      <td>80</td>\n",
              "      <td>00</td>\n",
              "      <td>ff</td>\n",
              "      <td>22</td>\n",
              "      <td>80</td>\n",
              "      <td>06</td>\n",
              "      <td>e4</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.478198e+09</td>\n",
              "      <td>0316</td>\n",
              "      <td>8</td>\n",
              "      <td>05</td>\n",
              "      <td>22</td>\n",
              "      <td>7c</td>\n",
              "      <td>09</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>00</td>\n",
              "      <td>6f</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.478201e+09</td>\n",
              "      <td>04f0</td>\n",
              "      <td>8</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>80</td>\n",
              "      <td>00</td>\n",
              "      <td>69</td>\n",
              "      <td>d1</td>\n",
              "      <td>13</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.478198e+09</td>\n",
              "      <td>0359</td>\n",
              "      <td>8</td>\n",
              "      <td>ed</td>\n",
              "      <td>28</td>\n",
              "      <td>fa</td>\n",
              "      <td>f5</td>\n",
              "      <td>34</td>\n",
              "      <td>e3</td>\n",
              "      <td>17</td>\n",
              "      <td>bd</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e88421-cd76-42ae-b818-8e9b020de728')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37e88421-cd76-42ae-b818-8e9b020de728 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37e88421-cd76-42ae-b818-8e9b020de728');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0bcd6fa-8b7c-4342-8caa-dff735a4c121\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0bcd6fa-8b7c-4342-8caa-dff735a4c121')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0bcd6fa-8b7c-4342-8caa-dff735a4c121 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 9000,\n  \"fields\": [\n    {\n      \"column\": \"1478195721.903877\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1624.9092045652235,\n        \"min\": 1478195722.192954,\n        \"max\": 1478201208.222218,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          1478197625.039605,\n          1478196250.618253,\n          1478196715.833358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0545\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1752,\n        \"samples\": [\n          \"02da\",\n          \"04fd\",\n          \"0549\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d8\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"78\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"c8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"77\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"8a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"a5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"fb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"c0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"9d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.5\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 256,\n        \"samples\": [\n          \"a8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"R\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o arquivo para examinar os dados\n",
        "file_path = \"/content/dos_df_proporcional_ajustado.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Verificar as primeiras linhas do dataset para compreender sua estrutura\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear as colunas para melhor compreensão\n",
        "data.columns = ['Timestamp', 'CAN_ID', 'DLC', 'DATA_0', 'DATA_1', 'DATA_2',\n",
        "                'DATA_3', 'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7', 'Flag']\n",
        "\n",
        "# Verificar se existem valores ausentes\n",
        "missing_data = data.isnull().sum()\n",
        "\n",
        "# Analisar a proporção de flags 'T' e 'R'\n",
        "flag_distribution = data['Flag'].value_counts(normalize=True)\n",
        "\n",
        "# Examinar estatísticas descritivas para colunas numéricas\n",
        "numeric_stats = data.describe()\n",
        "\n",
        "missing_data, flag_distribution, numeric_stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3FqQEfybDu3",
        "outputId": "2d61352d-1650-4830-8b56-bf89cacda1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp    0\n",
              " CAN_ID       0\n",
              " DLC          0\n",
              " DATA_0       0\n",
              " DATA_1       0\n",
              " DATA_2       0\n",
              " DATA_3       0\n",
              " DATA_4       0\n",
              " DATA_5       0\n",
              " DATA_6       0\n",
              " DATA_7       0\n",
              " Flag         0\n",
              " dtype: int64,\n",
              " Flag\n",
              " R    0.555556\n",
              " T    0.444444\n",
              " Name: proportion, dtype: float64,\n",
              "           Timestamp     DLC\n",
              " count  9.000000e+03  9000.0\n",
              " mean   1.478197e+09     8.0\n",
              " std    1.624909e+03     0.0\n",
              " min    1.478196e+09     8.0\n",
              " 25%    1.478196e+09     8.0\n",
              " 50%    1.478197e+09     8.0\n",
              " 75%    1.478198e+09     8.0\n",
              " max    1.478201e+09     8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter o Timestamp para um formato de data legível para análise temporal\n",
        "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s')\n",
        "\n",
        "# Criar uma nova coluna para armazenar apenas a hora das mensagens\n",
        "data['Hour'] = data['Timestamp'].dt.hour\n",
        "\n",
        "# Contar o número de mensagens por hora\n",
        "messages_per_hour = data.groupby('Hour').size()\n",
        "\n",
        "# Identificar quais CAN_IDs são mais frequentes\n",
        "can_id_distribution = data['CAN_ID'].value_counts().head(10)\n",
        "\n",
        "messages_per_hour, can_id_distribution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0bTd8Q3bFuU",
        "outputId": "93e6590e-91d1-48f7-8d2c-0d5da2e24e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Hour\n",
              " 17     873\n",
              " 18    6736\n",
              " 19    1391\n",
              " dtype: int64,\n",
              " CAN_ID\n",
              " 043f    316\n",
              " 0440    289\n",
              " 0260    288\n",
              " 02a0    285\n",
              " 02c0    284\n",
              " 0316    281\n",
              " 0153    273\n",
              " 0002    270\n",
              " 0370    269\n",
              " 0350    269\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição dos CAN_IDs em relação às flags 'T' e 'R'\n",
        "can_id_flag_distribution = data.groupby(['CAN_ID', 'Flag']).size().unstack(fill_value=0)\n",
        "\n",
        "# Explorar padrões nos campos 'DATA_X' para mensagens com flag 'T'\n",
        "data_injected = data[data['Flag'] == 'T']\n",
        "data_normal = data[data['Flag'] == 'R']\n",
        "\n",
        "# Calcular estatísticas descritivas para os campos 'DATA_X' para cada tipo de flag\n",
        "data_injected_stats = data_injected[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                     'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].describe()\n",
        "\n",
        "data_normal_stats = data_normal[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                 'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].describe()\n",
        "\n",
        "can_id_flag_distribution, data_injected_stats, data_normal_stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIg3F0ckbH5R",
        "outputId": "f433ce68-62e4-41f2-a4ea-c5216bcb7a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Flag      R  T\n",
              " CAN_ID        \n",
              " 0000      0  1\n",
              " 0001      0  3\n",
              " 0002    263  7\n",
              " 0003      0  1\n",
              " 0004      0  4\n",
              " ...     ... ..\n",
              " 07fa      0  4\n",
              " 07fb      0  2\n",
              " 07fc      0  3\n",
              " 07fe      0  1\n",
              " 07ff      0  1\n",
              " \n",
              " [1752 rows x 2 columns],\n",
              "        DATA_0 DATA_1 DATA_2 DATA_3 DATA_4 DATA_5 DATA_6 DATA_7\n",
              " count    4000   4000   4000   4000   4000   4000   4000   4000\n",
              " unique    256    256    256    256    256    256    256    256\n",
              " top        7e     5f     83     34     0e     46     ae     13\n",
              " freq       26     28     25     27     33     27     27     27,\n",
              "        DATA_0 DATA_1 DATA_2 DATA_3 DATA_4 DATA_5 DATA_6 DATA_7\n",
              " count    5000   5000   5000   5000   5000   5000   5000   5000\n",
              " unique     69     49     50     26    120    139     59    251\n",
              " top        00     00     00     00     00     00     00     00\n",
              " freq     1714   2044   2865   2216   2195   1609   2677   2594)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição temporal das mensagens com CAN_ID '0000' (flag 'T')\n",
        "injected_id_0000 = data[(data['CAN_ID'] == '0000') & (data['Flag'] == 'T')]\n",
        "\n",
        "# Contagem de mensagens injetadas por minuto\n",
        "injected_id_0000['Minute'] = injected_id_0000['Timestamp'].dt.minute\n",
        "injected_per_minute = injected_id_0000.groupby('Minute').size()\n",
        "\n",
        "# Explorar CAN_IDs que aparecem menos frequentemente para identificar possíveis outliers\n",
        "rare_can_ids = data['CAN_ID'].value_counts().tail(10)\n",
        "\n",
        "# Verificar se existem correlações entre os campos 'DATA_X' para as mensagens normais\n",
        "data_normal_numeric = data_normal[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                   'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].apply(lambda x: x.apply(int, base=16))\n",
        "correlation_matrix = data_normal_numeric.corr()\n",
        "\n",
        "injected_per_minute, rare_can_ids, correlation_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TujNMr8mbKVR",
        "outputId": "da8f6836-b402-4a45-c6f1-4d4a3e0c1d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8fa582d780b2>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  injected_id_0000['Minute'] = injected_id_0000['Timestamp'].dt.minute\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Minute\n",
              " 7    1\n",
              " dtype: int64,\n",
              " CAN_ID\n",
              " 0637    1\n",
              " 0365    1\n",
              " 0794    1\n",
              " 012b    1\n",
              " 04c8    1\n",
              " 0730    1\n",
              " 05ed    1\n",
              " 0274    1\n",
              " 074a    1\n",
              " 01a3    1\n",
              " Name: count, dtype: int64,\n",
              "           DATA_0    DATA_1    DATA_2    DATA_3    DATA_4    DATA_5    DATA_6  \\\n",
              " DATA_0  1.000000  0.173661 -0.180856 -0.207755  0.266923  0.099619 -0.134284   \n",
              " DATA_1  0.173661  1.000000  0.165328  0.195718 -0.086909  0.185022 -0.273766   \n",
              " DATA_2 -0.180856  0.165328  1.000000  0.091638  0.317471 -0.122777  0.269925   \n",
              " DATA_3 -0.207755  0.195718  0.091638  1.000000  0.087645  0.582435 -0.038304   \n",
              " DATA_4  0.266923 -0.086909  0.317471  0.087645  1.000000  0.333615  0.140847   \n",
              " DATA_5  0.099619  0.185022 -0.122777  0.582435  0.333615  1.000000 -0.007733   \n",
              " DATA_6 -0.134284 -0.273766  0.269925 -0.038304  0.140847 -0.007733  1.000000   \n",
              " DATA_7 -0.234620  0.136150  0.100103 -0.043233 -0.069945 -0.155275 -0.142880   \n",
              " \n",
              "           DATA_7  \n",
              " DATA_0 -0.234620  \n",
              " DATA_1  0.136150  \n",
              " DATA_2  0.100103  \n",
              " DATA_3 -0.043233  \n",
              " DATA_4 -0.069945  \n",
              " DATA_5 -0.155275  \n",
              " DATA_6 -0.142880  \n",
              " DATA_7  1.000000  )"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter os campos 'DATA_X' para valores numéricos para análise de correlação\n",
        "data_numeric = data[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                     'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].apply(lambda x: x.apply(int, base=16))\n",
        "\n",
        "# Adicionar a flag como numérica (T = 1, R = 0) para facilitar a análise\n",
        "data_numeric['Flag'] = data['Flag'].apply(lambda x: 1 if x == 'T' else 0)\n",
        "\n",
        "# Calcular a correlação entre os campos de dados e a flag\n",
        "correlation_with_flag = data_numeric.corr()['Flag'].drop('Flag')\n",
        "\n",
        "correlation_with_flag\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "uvkaERJkbOoU",
        "outputId": "98709c7d-da1a-4d44-dfe7-feaeb412f715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATA_0    0.373055\n",
              "DATA_1    0.548602\n",
              "DATA_2    0.566564\n",
              "DATA_3    0.334792\n",
              "DATA_4    0.465301\n",
              "DATA_5    0.338721\n",
              "DATA_6    0.610562\n",
              "DATA_7    0.490871\n",
              "Name: Flag, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DATA_0</th>\n",
              "      <td>0.373055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_1</th>\n",
              "      <td>0.548602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_2</th>\n",
              "      <td>0.566564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_3</th>\n",
              "      <td>0.334792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_4</th>\n",
              "      <td>0.465301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_5</th>\n",
              "      <td>0.338721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_6</th>\n",
              "      <td>0.610562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_7</th>\n",
              "      <td>0.490871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando o modelo de Regressão Logística\n",
        "model_minmax = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='lbfgs',\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinando o modelo com os dados de treino\n",
        "model_minmax.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliando no conjunto de treino\n",
        "y_train_pred = model_minmax.predict(X_train_scaled)\n",
        "y_train_prob = model_minmax.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics(y_train, y_train_pred, y_train_prob, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliando no conjunto de teste\n",
        "y_test_pred = model_minmax.predict(X_test_scaled)\n",
        "y_test_prob = model_minmax.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics(y_test, y_test_pred, y_test_prob, \"Teste\")\n",
        "\n",
        "# Avaliando no conjunto de validação\n",
        "y_val_pred = model_minmax.predict(X_val_scaled)\n",
        "y_val_prob = model_minmax.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics(y_val, y_val_pred, y_val_prob, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmfDTUTpbR0D",
        "outputId": "6437b5a9-5582-49dc-8ff0-f63dd12ae5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9561\n",
            "Precisão: 0.9749\n",
            "Recall: 0.9263\n",
            "F1-Score: 0.9500\n",
            "AUC-ROC: 0.9871\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2912   58]\n",
            " [ 179 2251]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9594\n",
            "Precisão: 0.9688\n",
            "Recall: 0.9382\n",
            "F1-Score: 0.9532\n",
            "AUC-ROC: 0.9912\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[983  24]\n",
            " [ 49 744]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9589\n",
            "Precisão: 0.9693\n",
            "Recall: 0.9344\n",
            "F1-Score: 0.9515\n",
            "AUC-ROC: 0.9901\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1000   23]\n",
            " [  51  726]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo Random Forest com regularização\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_rf(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_rf = model_rf.predict(X_train_scaled)\n",
        "y_train_prob_rf = model_rf.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_rf(y_train, y_train_pred_rf, y_train_prob_rf, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_rf = model_rf.predict(X_test_scaled)\n",
        "y_test_prob_rf = model_rf.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_rf(y_test, y_test_pred_rf, y_test_prob_rf, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_rf = model_rf.predict(X_val_scaled)\n",
        "y_val_prob_rf = model_rf.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_rf(y_val, y_val_pred_rf, y_val_prob_rf, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoaJ_B9_fIJy",
        "outputId": "e734e841-8cd5-46fb-c528-7448e1beadf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo de Árvore de Decisão com regularização\n",
        "model_tree = DecisionTreeClassifier(\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_tree(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_tree = model_tree.predict(X_train_scaled)\n",
        "y_train_prob_tree = model_tree.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_tree(y_train, y_train_pred_tree, y_train_prob_tree, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_tree = model_tree.predict(X_test_scaled)\n",
        "y_test_prob_tree = model_tree.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_tree(y_test, y_test_pred_tree, y_test_prob_tree, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_tree = model_tree.predict(X_val_scaled)\n",
        "y_val_prob_tree = model_tree.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_tree(y_val, y_val_pred_tree, y_val_prob_tree, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYiVcoKUhBA4",
        "outputId": "2aaeba67-34d2-47dc-abbd-cc1e0f1b13ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9978\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9951\n",
            "F1-Score: 0.9975\n",
            "AUC-ROC: 0.9996\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [  12 2418]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9972\n",
            "Precisão: 0.9987\n",
            "Recall: 0.9950\n",
            "F1-Score: 0.9968\n",
            "AUC-ROC: 0.9976\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1006    1]\n",
            " [   4  789]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9950\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9884\n",
            "F1-Score: 0.9942\n",
            "AUC-ROC: 0.9959\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   9  768]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo de Gradient Boosting\n",
        "model_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_gb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_gb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_gb = model_gb.predict(X_train_scaled)\n",
        "y_train_prob_gb = model_gb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_gb(y_train, y_train_pred_gb, y_train_prob_gb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_gb = model_gb.predict(X_test_scaled)\n",
        "y_test_prob_gb = model_gb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_gb(y_test, y_test_pred_gb, y_test_prob_gb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_gb = model_gb.predict(X_val_scaled)\n",
        "y_val_prob_gb = model_gb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_gb(y_val, y_val_pred_gb, y_val_prob_gb, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvBtNbmBiJ-P",
        "outputId": "f73a6a2f-cc7e-4c54-9f98-8af5cc785d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9983\n",
            "Precisão: 0.9975\n",
            "Recall: 0.9987\n",
            "F1-Score: 0.9981\n",
            "AUC-ROC: 0.9995\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1005    2]\n",
            " [   1  792]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9967\n",
            "Precisão: 0.9974\n",
            "Recall: 0.9949\n",
            "F1-Score: 0.9961\n",
            "AUC-ROC: 0.9976\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1021    2]\n",
            " [   4  773]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo K-Nearest Neighbors\n",
        "model_knn = KNeighborsClassifier(\n",
        "    n_neighbors=5,\n",
        "    weights='uniform',\n",
        "    metric='minkowski',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_knn(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_knn = model_knn.predict(X_train_scaled)\n",
        "y_train_prob_knn = model_knn.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_knn(y_train, y_train_pred_knn, y_train_prob_knn, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_knn = model_knn.predict(X_test_scaled)\n",
        "y_test_prob_knn = model_knn.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_knn(y_test, y_test_pred_knn, y_test_prob_knn, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_knn = model_knn.predict(X_val_scaled)\n",
        "y_val_prob_knn = model_knn.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_knn(y_val, y_val_pred_knn, y_val_prob_knn, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5UYQDmmjRQR",
        "outputId": "cf19d771-edca-4f43-ac5a-78363037e1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9948\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9885\n",
            "F1-Score: 0.9942\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [  28 2402]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9944\n",
            "Precisão: 0.9987\n",
            "Recall: 0.9887\n",
            "F1-Score: 0.9937\n",
            "AUC-ROC: 0.9970\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1006    1]\n",
            " [   9  784]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9928\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9833\n",
            "F1-Score: 0.9916\n",
            "AUC-ROC: 0.9968\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [  13  764]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo SVM\n",
        "model_svm = SVC(\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    probability=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_svm(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_svm = model_svm.predict(X_train_scaled)\n",
        "y_train_prob_svm = model_svm.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_svm(y_train, y_train_pred_svm, y_train_prob_svm, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_svm = model_svm.predict(X_test_scaled)\n",
        "y_test_prob_svm = model_svm.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_svm(y_test, y_test_pred_svm, y_test_prob_svm, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_svm = model_svm.predict(X_val_scaled)\n",
        "y_val_prob_svm = model_svm.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_svm(y_val, y_val_pred_svm, y_val_prob_svm, \"Validação\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwUOkVFDmFkE",
        "outputId": "ced091b0-dbb7-4225-f044-0440a8230425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9965\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9922\n",
            "F1-Score: 0.9961\n",
            "AUC-ROC: 0.9996\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [  19 2411]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9983\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9962\n",
            "F1-Score: 0.9981\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   3  790]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9972\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9936\n",
            "F1-Score: 0.9968\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   5  772]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo XGBoost\n",
        "model_xgb = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=10,\n",
        "    min_child_weight=1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_xgb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_xgb = model_xgb.predict(X_train_scaled)\n",
        "y_train_prob_xgb = model_xgb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_xgb(y_train, y_train_pred_xgb, y_train_prob_xgb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_xgb = model_xgb.predict(X_test_scaled)\n",
        "y_test_prob_xgb = model_xgb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_xgb(y_test, y_test_pred_xgb, y_test_prob_xgb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_xgb = model_xgb.predict(X_val_scaled)\n",
        "y_val_prob_xgb = model_xgb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_xgb(y_val, y_val_pred_xgb, y_val_prob_xgb, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNokTQ1DowJW",
        "outputId": "fd8cde97-5e32-44cf-d90d-1c2d1b5e0202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [16:36:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9994\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9987\n",
            "F1-Score: 0.9994\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   1  776]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo CatBoost\n",
        "model_cb = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=10,\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "model_cb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_cb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_cb = model_cb.predict(X_train_scaled)\n",
        "y_train_prob_cb = model_cb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_cb(y_train, y_train_pred_cb, y_train_prob_cb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_cb = model_cb.predict(X_test_scaled)\n",
        "y_test_prob_cb = model_cb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_cb(y_test, y_test_pred_cb, y_test_prob_cb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_cb = model_cb.predict(X_val_scaled)\n",
        "y_val_prob_cb = model_cb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_cb(y_val, y_val_pred_cb, y_val_prob_cb, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1bcOURixBnV",
        "outputId": "b79111b5-bfec-490d-89ba-f297ebec4f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9989\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9975\n",
            "F1-Score: 0.9987\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   2  791]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9989\n",
            "Precisão: 1.0000\n",
            "Recall: 0.9974\n",
            "F1-Score: 0.9987\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   2  775]]\n"
          ]
        }
      ]
    }
  ]
}