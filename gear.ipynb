{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNISbyddHJ0m1ZebCUKp9pl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanpereirax/Intrusion-detector-with-supervised-models/blob/main/gear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCeTxETp6xGm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GjRPJtkx0JwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gear_df = pd.read_csv('/content/gear_dataset.csv')\n"
      ],
      "metadata": {
        "id": "LrPgYG8MzBub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amostras de 1% do Dataset Original\n",
        "amostras_R = gear_df[gear_df['R'] == 'R'].sample(n=5_000, random_state=42)\n",
        "amostras_T = gear_df[gear_df['R'] == 'T'].sample(n=4_000, random_state=42)\n",
        "gear_df_balanceado = pd.concat([amostras_R, amostras_T]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "gear_df_balanceado.to_csv('gear_df_proporcional_ajustado.csv', index=False)"
      ],
      "metadata": {
        "id": "qfEawR5yzEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVjFKk3Lwq7K",
        "outputId": "7bbbceae-a4f4-4336-a773-33de1d317cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QFiFcb8wwpz",
        "outputId": "15af1d72-85aa-485c-d497-2fb803cf2571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kvnxvFxsaLZL",
        "outputId": "6cd94a51-37ce-4ac7-dbb9-bb538fc168eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1478193190.056566  0140  8  00 00.1 00.2 00.3  10  29  2a  24  R\n",
              "0       1.478195e+09  043f  8  01   45   60   ff  6b  00  00  00  T\n",
              "1       1.478194e+09  0329  8  0c   bb   7f   14  11  20  00  14  R\n",
              "2       1.478194e+09  0002  8  00   00   00   00  00  09  08  f4  R\n",
              "3       1.478195e+09  0140  8  00   00   00   00  1c  07  2b  a9  R\n",
              "4       1.478194e+09  043f  8  01   45   60   ff  6b  00  00  00  T"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a13001d3-66e5-4349-af74-57fb0b5e6d36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1478193190.056566</th>\n",
              "      <th>0140</th>\n",
              "      <th>8</th>\n",
              "      <th>00</th>\n",
              "      <th>00.1</th>\n",
              "      <th>00.2</th>\n",
              "      <th>00.3</th>\n",
              "      <th>10</th>\n",
              "      <th>29</th>\n",
              "      <th>2a</th>\n",
              "      <th>24</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.478195e+09</td>\n",
              "      <td>043f</td>\n",
              "      <td>8</td>\n",
              "      <td>01</td>\n",
              "      <td>45</td>\n",
              "      <td>60</td>\n",
              "      <td>ff</td>\n",
              "      <td>6b</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.478194e+09</td>\n",
              "      <td>0329</td>\n",
              "      <td>8</td>\n",
              "      <td>0c</td>\n",
              "      <td>bb</td>\n",
              "      <td>7f</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>20</td>\n",
              "      <td>00</td>\n",
              "      <td>14</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.478194e+09</td>\n",
              "      <td>0002</td>\n",
              "      <td>8</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>09</td>\n",
              "      <td>08</td>\n",
              "      <td>f4</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.478195e+09</td>\n",
              "      <td>0140</td>\n",
              "      <td>8</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>1c</td>\n",
              "      <td>07</td>\n",
              "      <td>2b</td>\n",
              "      <td>a9</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.478194e+09</td>\n",
              "      <td>043f</td>\n",
              "      <td>8</td>\n",
              "      <td>01</td>\n",
              "      <td>45</td>\n",
              "      <td>60</td>\n",
              "      <td>ff</td>\n",
              "      <td>6b</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a13001d3-66e5-4349-af74-57fb0b5e6d36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a13001d3-66e5-4349-af74-57fb0b5e6d36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a13001d3-66e5-4349-af74-57fb0b5e6d36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-71d90d68-542e-44a9-9a72-b489958d2adc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71d90d68-542e-44a9-9a72-b489958d2adc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-71d90d68-542e-44a9-9a72-b489958d2adc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 9000,\n  \"fields\": [\n    {\n      \"column\": \"1478193190.056566\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2377.5511157340334,\n        \"min\": 1478193190.484387,\n        \"max\": 1478201209.020821,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          1478194826.58429,\n          1478193408.992315,\n          1478194634.326021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0140\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"0260\",\n          \"0350\",\n          \"043f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 87,\n        \"samples\": [\n          \"5a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 95,\n        \"samples\": [\n          \"55\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"78\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00.3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"86\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"10\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 118,\n        \"samples\": [\n          \"0a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"29\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 232,\n        \"samples\": [\n          \"9f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          \"49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"24\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 252,\n        \"samples\": [\n          \"ab\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"R\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o arquivo para examinar os dados\n",
        "file_path = \"/content/gear_df_proporcional_ajustado.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Verificar as primeiras linhas do dataset para compreender sua estrutura\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear as colunas para melhor compreensão\n",
        "data.columns = ['Timestamp', 'CAN_ID', 'DLC', 'DATA_0', 'DATA_1', 'DATA_2',\n",
        "                'DATA_3', 'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7', 'Flag']\n",
        "\n",
        "# Verificar se existem valores ausentes\n",
        "missing_data = data.isnull().sum()\n",
        "\n",
        "# Analisar a proporção de flags 'T' e 'R'\n",
        "flag_distribution = data['Flag'].value_counts(normalize=True)\n",
        "\n",
        "# Examinar estatísticas descritivas para colunas numéricas\n",
        "numeric_stats = data.describe()\n",
        "\n",
        "missing_data, flag_distribution, numeric_stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3FqQEfybDu3",
        "outputId": "d2b036d9-7a4f-46a9-9fd4-8286aab61658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp    0\n",
              " CAN_ID       0\n",
              " DLC          0\n",
              " DATA_0       0\n",
              " DATA_1       0\n",
              " DATA_2       0\n",
              " DATA_3       0\n",
              " DATA_4       0\n",
              " DATA_5       0\n",
              " DATA_6       0\n",
              " DATA_7       0\n",
              " Flag         0\n",
              " dtype: int64,\n",
              " Flag\n",
              " R    0.555556\n",
              " T    0.444444\n",
              " Name: proportion, dtype: float64,\n",
              "           Timestamp     DLC\n",
              " count  9.000000e+03  9000.0\n",
              " mean   1.478195e+09     8.0\n",
              " std    2.377551e+03     0.0\n",
              " min    1.478193e+09     8.0\n",
              " 25%    1.478194e+09     8.0\n",
              " 50%    1.478194e+09     8.0\n",
              " 75%    1.478195e+09     8.0\n",
              " max    1.478201e+09     8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter o Timestamp para um formato de data legível para análise temporal\n",
        "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s')\n",
        "\n",
        "# Criar uma nova coluna para armazenar apenas a hora das mensagens\n",
        "data['Hour'] = data['Timestamp'].dt.hour\n",
        "\n",
        "# Contar o número de mensagens por hora\n",
        "messages_per_hour = data.groupby('Hour').size()\n",
        "\n",
        "# Identificar quais CAN_IDs são mais frequentes\n",
        "can_id_distribution = data['CAN_ID'].value_counts().head(10)\n",
        "\n",
        "messages_per_hour, can_id_distribution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0bTd8Q3bFuU",
        "outputId": "d73235d3-88be-4f96-9313-5005078ed1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Hour\n",
              " 17    7795\n",
              " 19    1205\n",
              " dtype: int64,\n",
              " CAN_ID\n",
              " 043f    4302\n",
              " 0316     303\n",
              " 0131     296\n",
              " 0260     291\n",
              " 0350     291\n",
              " 0002     282\n",
              " 0153     274\n",
              " 02c0     272\n",
              " 0545     272\n",
              " 0440     262\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição dos CAN_IDs em relação às flags 'T' e 'R'\n",
        "can_id_flag_distribution = data.groupby(['CAN_ID', 'Flag']).size().unstack(fill_value=0)\n",
        "\n",
        "# Explorar padrões nos campos 'DATA_X' para mensagens com flag 'T'\n",
        "data_injected = data[data['Flag'] == 'T']\n",
        "data_normal = data[data['Flag'] == 'R']\n",
        "\n",
        "# Calcular estatísticas descritivas para os campos 'DATA_X' para cada tipo de flag\n",
        "data_injected_stats = data_injected[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                     'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].describe()\n",
        "\n",
        "data_normal_stats = data_normal[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                 'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].describe()\n",
        "\n",
        "can_id_flag_distribution, data_injected_stats, data_normal_stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIg3F0ckbH5R",
        "outputId": "8d7ebb93-8487-4acf-8047-03b6a9c1f41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Flag      R     T\n",
              " CAN_ID           \n",
              " 0002    282     0\n",
              " 00a0     30     0\n",
              " 00a1     25     0\n",
              " 0130    246     0\n",
              " 0131    296     0\n",
              " 0140    232     0\n",
              " 0153    274     0\n",
              " 018f    251     0\n",
              " 01f1    127     0\n",
              " 0260    291     0\n",
              " 02a0    260     0\n",
              " 02c0    272     0\n",
              " 0316    303     0\n",
              " 0329    252     0\n",
              " 0350    291     0\n",
              " 0370    261     0\n",
              " 0430    136     0\n",
              " 043f    302  4000\n",
              " 0440    262     0\n",
              " 04b1    168     0\n",
              " 04f0    140     0\n",
              " 0545    272     0\n",
              " 05a0      4     0\n",
              " 05a2      3     0\n",
              " 0690     20     0,\n",
              "        DATA_0 DATA_1 DATA_2 DATA_3 DATA_4 DATA_5 DATA_6 DATA_7\n",
              " count    4000   4000   4000   4000   4000   4000   4000   4000\n",
              " unique      1      1      1      1      1      1      1      1\n",
              " top        01     45     60     ff     6b     00     00     00\n",
              " freq     4000   4000   4000   4000   4000   4000   4000   4000,\n",
              "        DATA_0 DATA_1 DATA_2 DATA_3 DATA_4 DATA_5 DATA_6 DATA_7\n",
              " count    5000   5000   5000   5000   5000   5000   5000   5000\n",
              " unique     87     95     92     32    117    232     96    252\n",
              " top        00     00     00     00     00     00     00     00\n",
              " freq     1652   2072   2944   2292   2226   1631   2706   2631)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição temporal das mensagens com CAN_ID '0000' (flag 'T')\n",
        "injected_id_0000 = data[(data['CAN_ID'] == '0000') & (data['Flag'] == 'T')]\n",
        "\n",
        "# Contagem de mensagens injetadas por minuto\n",
        "injected_id_0000['Minute'] = injected_id_0000['Timestamp'].dt.minute\n",
        "injected_per_minute = injected_id_0000.groupby('Minute').size()\n",
        "\n",
        "# Explorar CAN_IDs que aparecem menos frequentemente para identificar possíveis outliers\n",
        "rare_can_ids = data['CAN_ID'].value_counts().tail(10)\n",
        "\n",
        "# Verificar se existem correlações entre os campos 'DATA_X' para as mensagens normais\n",
        "data_normal_numeric = data_normal[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                   'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].apply(lambda x: x.apply(int, base=16))\n",
        "correlation_matrix = data_normal_numeric.corr()\n",
        "\n",
        "injected_per_minute, rare_can_ids, correlation_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TujNMr8mbKVR",
        "outputId": "05ecd2f2-d44e-4df2-a842-b50adb86779b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Series([], dtype: int64),\n",
              " CAN_ID\n",
              " 0140    232\n",
              " 04b1    168\n",
              " 04f0    140\n",
              " 0430    136\n",
              " 01f1    127\n",
              " 00a0     30\n",
              " 00a1     25\n",
              " 0690     20\n",
              " 05a0      4\n",
              " 05a2      3\n",
              " Name: count, dtype: int64,\n",
              "           DATA_0    DATA_1    DATA_2    DATA_3    DATA_4    DATA_5    DATA_6  \\\n",
              " DATA_0  1.000000  0.204351 -0.162079 -0.181394  0.263065  0.044748 -0.138313   \n",
              " DATA_1  0.204351  1.000000  0.172492  0.179451 -0.078704  0.227565 -0.262268   \n",
              " DATA_2 -0.162079  0.172492  1.000000  0.071469  0.299982 -0.148354  0.203993   \n",
              " DATA_3 -0.181394  0.179451  0.071469  1.000000  0.085070  0.544646 -0.024029   \n",
              " DATA_4  0.263065 -0.078704  0.299982  0.085070  1.000000  0.147111  0.151153   \n",
              " DATA_5  0.044748  0.227565 -0.148354  0.544646  0.147111  1.000000  0.037197   \n",
              " DATA_6 -0.138313 -0.262268  0.203993 -0.024029  0.151153  0.037197  1.000000   \n",
              " DATA_7 -0.229336  0.141162  0.127824 -0.049289 -0.028068 -0.065141 -0.126507   \n",
              " \n",
              "           DATA_7  \n",
              " DATA_0 -0.229336  \n",
              " DATA_1  0.141162  \n",
              " DATA_2  0.127824  \n",
              " DATA_3 -0.049289  \n",
              " DATA_4 -0.028068  \n",
              " DATA_5 -0.065141  \n",
              " DATA_6 -0.126507  \n",
              " DATA_7  1.000000  )"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter os campos 'DATA_X' para valores numéricos para análise de correlação\n",
        "data_numeric = data[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                     'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].apply(lambda x: x.apply(int, base=16))\n",
        "\n",
        "# Adicionar a flag como numérica (T = 1, R = 0) para facilitar a análise\n",
        "data_numeric['Flag'] = data['Flag'].apply(lambda x: 1 if x == 'T' else 0)\n",
        "\n",
        "# Calcular a correlação entre os campos de dados e a flag\n",
        "correlation_with_flag = data_numeric.corr()['Flag'].drop('Flag')\n",
        "\n",
        "correlation_with_flag\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "uvkaERJkbOoU",
        "outputId": "97d32ea5-24b1-4dc9-fa93-3a29f2f630df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATA_0   -0.384587\n",
              "DATA_1    0.304419\n",
              "DATA_2    0.517737\n",
              "DATA_3    0.804643\n",
              "DATA_4    0.499274\n",
              "DATA_5   -0.475713\n",
              "DATA_6   -0.292928\n",
              "DATA_7   -0.402112\n",
              "Name: Flag, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DATA_0</th>\n",
              "      <td>-0.384587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_1</th>\n",
              "      <td>0.304419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_2</th>\n",
              "      <td>0.517737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_3</th>\n",
              "      <td>0.804643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_4</th>\n",
              "      <td>0.499274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_5</th>\n",
              "      <td>-0.475713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_6</th>\n",
              "      <td>-0.292928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_7</th>\n",
              "      <td>-0.402112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando o modelo de Regressão Logística\n",
        "model_minmax = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='lbfgs',\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinando o modelo com os dados de treino\n",
        "model_minmax.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliando no conjunto de treino\n",
        "y_train_pred = model_minmax.predict(X_train_scaled)\n",
        "y_train_prob = model_minmax.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics(y_train, y_train_pred, y_train_prob, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliando no conjunto de teste\n",
        "y_test_pred = model_minmax.predict(X_test_scaled)\n",
        "y_test_prob = model_minmax.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics(y_test, y_test_pred, y_test_prob, \"Teste\")\n",
        "\n",
        "# Avaliando no conjunto de validação\n",
        "y_val_pred = model_minmax.predict(X_val_scaled)\n",
        "y_val_prob = model_minmax.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics(y_val, y_val_pred, y_val_prob, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmfDTUTpbR0D",
        "outputId": "23771457-eb30-49ff-c138-2b006c5beee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9893\n",
            "Precisão: 0.9767\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9882\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2912   58]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9878\n",
            "Precisão: 0.9730\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9863\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[985  22]\n",
            " [  0 793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9878\n",
            "Precisão: 0.9725\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9860\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1001   22]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo Random Forest com regularização\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_rf(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_rf = model_rf.predict(X_train_scaled)\n",
        "y_train_prob_rf = model_rf.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_rf(y_train, y_train_pred_rf, y_train_prob_rf, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_rf = model_rf.predict(X_test_scaled)\n",
        "y_test_prob_rf = model_rf.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_rf(y_test, y_test_pred_rf, y_test_prob_rf, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_rf = model_rf.predict(X_val_scaled)\n",
        "y_val_prob_rf = model_rf.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_rf(y_val, y_val_pred_rf, y_val_prob_rf, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoaJ_B9_fIJy",
        "outputId": "17b4d9c0-75bb-4bcb-bc9a-f2a46ad6112a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo de Árvore de Decisão com regularização\n",
        "model_tree = DecisionTreeClassifier(\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_tree(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_tree = model_tree.predict(X_train_scaled)\n",
        "y_train_prob_tree = model_tree.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_tree(y_train, y_train_pred_tree, y_train_prob_tree, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_tree = model_tree.predict(X_test_scaled)\n",
        "y_test_prob_tree = model_tree.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_tree(y_test, y_test_pred_tree, y_test_prob_tree, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_tree = model_tree.predict(X_val_scaled)\n",
        "y_val_prob_tree = model_tree.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_tree(y_val, y_val_pred_tree, y_val_prob_tree, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYiVcoKUhBA4",
        "outputId": "201ff296-b0c4-4698-e357-467e1deb7956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9998\n",
            "Precisão: 0.9996\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9998\n",
            "AUC-ROC: 0.9998\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2969    1]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo de Gradient Boosting\n",
        "model_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_gb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_gb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_gb = model_gb.predict(X_train_scaled)\n",
        "y_train_prob_gb = model_gb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_gb(y_train, y_train_pred_gb, y_train_prob_gb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_gb = model_gb.predict(X_test_scaled)\n",
        "y_test_prob_gb = model_gb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_gb(y_test, y_test_pred_gb, y_test_prob_gb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_gb = model_gb.predict(X_val_scaled)\n",
        "y_val_prob_gb = model_gb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_gb(y_val, y_val_pred_gb, y_val_prob_gb, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvBtNbmBiJ-P",
        "outputId": "18161194-620f-4762-abda-77235bb0d4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo K-Nearest Neighbors\n",
        "model_knn = KNeighborsClassifier(\n",
        "    n_neighbors=5,\n",
        "    weights='uniform',\n",
        "    metric='minkowski',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_knn(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_knn = model_knn.predict(X_train_scaled)\n",
        "y_train_prob_knn = model_knn.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_knn(y_train, y_train_pred_knn, y_train_prob_knn, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_knn = model_knn.predict(X_test_scaled)\n",
        "y_test_prob_knn = model_knn.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_knn(y_test, y_test_pred_knn, y_test_prob_knn, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_knn = model_knn.predict(X_val_scaled)\n",
        "y_val_prob_knn = model_knn.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_knn(y_val, y_val_pred_knn, y_val_prob_knn, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5UYQDmmjRQR",
        "outputId": "36da98b0-9b17-4215-81b4-7ccaf1aa53de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo SVM\n",
        "model_svm = SVC(\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    probability=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_svm(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_svm = model_svm.predict(X_train_scaled)\n",
        "y_train_prob_svm = model_svm.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_svm(y_train, y_train_pred_svm, y_train_prob_svm, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_svm = model_svm.predict(X_test_scaled)\n",
        "y_test_prob_svm = model_svm.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_svm(y_test, y_test_pred_svm, y_test_prob_svm, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_svm = model_svm.predict(X_val_scaled)\n",
        "y_val_prob_svm = model_svm.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_svm(y_val, y_val_pred_svm, y_val_prob_svm, \"Validação\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwUOkVFDmFkE",
        "outputId": "dcdb1960-91fc-4f76-80bd-e1916861d79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9985\n",
            "Precisão: 0.9967\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9984\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2962    8]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9989\n",
            "Precisão: 0.9975\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9987\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1005    2]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 0.9989\n",
            "Precisão: 0.9974\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9987\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1021    2]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo XGBoost\n",
        "model_xgb = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=10,\n",
        "    min_child_weight=1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_xgb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_xgb = model_xgb.predict(X_train_scaled)\n",
        "y_train_prob_xgb = model_xgb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_xgb(y_train, y_train_pred_xgb, y_train_prob_xgb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_xgb = model_xgb.predict(X_test_scaled)\n",
        "y_test_prob_xgb = model_xgb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_xgb(y_test, y_test_pred_xgb, y_test_prob_xgb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_xgb = model_xgb.predict(X_val_scaled)\n",
        "y_val_prob_xgb = model_xgb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_xgb(y_val, y_val_pred_xgb, y_val_prob_xgb, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNokTQ1DowJW",
        "outputId": "1a743a39-11ab-4fff-c5de-dc9eba20b680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [16:45:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo CatBoost\n",
        "model_cb = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=10,\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "model_cb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_cb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_cb = model_cb.predict(X_train_scaled)\n",
        "y_train_prob_cb = model_cb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_cb(y_train, y_train_pred_cb, y_train_prob_cb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_cb = model_cb.predict(X_test_scaled)\n",
        "y_test_prob_cb = model_cb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_cb(y_test, y_test_pred_cb, y_test_prob_cb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_cb = model_cb.predict(X_val_scaled)\n",
        "y_val_prob_cb = model_cb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_cb(y_val, y_val_pred_cb, y_val_prob_cb, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1bcOURixBnV",
        "outputId": "70463725-40a8-4ac0-fb4d-b0cbc8d6a1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    }
  ]
}