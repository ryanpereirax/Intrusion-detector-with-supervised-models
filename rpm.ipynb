{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHUPTrI45n2RJxhGFvVRjl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanpereirax/Intrusion-detector-with-supervised-models/blob/main/rpm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJX0Gldx60WA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GjRPJtkx0JwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rpm_df = pd.read_csv('/content/RPM_dataset.csv')\n"
      ],
      "metadata": {
        "id": "LrPgYG8MzBub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amostras de 1% do Dataset Original\n",
        "amostras_R = rpm_df[rpm_df['R'] == 'R'].sample(n=5_000, random_state=42)\n",
        "amostras_T = rpm_df[rpm_df['R'] == 'T'].sample(n=4_000, random_state=42)\n",
        "rpm_df_balanceado = pd.concat([amostras_R, amostras_T]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "rpm_df_balanceado.to_csv('rpm_df_proporcional_ajustado.csv', index=False)"
      ],
      "metadata": {
        "id": "qfEawR5yzEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVjFKk3Lwq7K",
        "outputId": "a299b062-4be8-4805-a361-2d15b59d6932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QFiFcb8wwpz",
        "outputId": "5c87937f-cc52-415b-bda3-bdeb61e7ce79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kvnxvFxsaLZL",
        "outputId": "7b60b711-26d1-4506-804f-5b28f2189cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   1478191030.045114  0316  8  05  22  68  09 22.1  20  00  75  R\n",
              "0       1.478191e+09  0316  8  45  29  24  ff   29  24  00  ff  T\n",
              "1       1.478192e+09  0690  8  00  00  01  00   a0  02  00  00  R\n",
              "2       1.478201e+09  02c0  8  14  00  00  00   00  00  00  00  R\n",
              "3       1.478192e+09  0350  8  05  20  e4  68   76  00  00  df  R\n",
              "4       1.478193e+09  0316  8  45  29  24  ff   29  24  00  ff  T"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f76ae68-02d0-445e-8d25-21e54f2c307c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1478191030.045114</th>\n",
              "      <th>0316</th>\n",
              "      <th>8</th>\n",
              "      <th>05</th>\n",
              "      <th>22</th>\n",
              "      <th>68</th>\n",
              "      <th>09</th>\n",
              "      <th>22.1</th>\n",
              "      <th>20</th>\n",
              "      <th>00</th>\n",
              "      <th>75</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.478191e+09</td>\n",
              "      <td>0316</td>\n",
              "      <td>8</td>\n",
              "      <td>45</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>ff</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>00</td>\n",
              "      <td>ff</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.478192e+09</td>\n",
              "      <td>0690</td>\n",
              "      <td>8</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>01</td>\n",
              "      <td>00</td>\n",
              "      <td>a0</td>\n",
              "      <td>02</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.478201e+09</td>\n",
              "      <td>02c0</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.478192e+09</td>\n",
              "      <td>0350</td>\n",
              "      <td>8</td>\n",
              "      <td>05</td>\n",
              "      <td>20</td>\n",
              "      <td>e4</td>\n",
              "      <td>68</td>\n",
              "      <td>76</td>\n",
              "      <td>00</td>\n",
              "      <td>00</td>\n",
              "      <td>df</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.478193e+09</td>\n",
              "      <td>0316</td>\n",
              "      <td>8</td>\n",
              "      <td>45</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>ff</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>00</td>\n",
              "      <td>ff</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f76ae68-02d0-445e-8d25-21e54f2c307c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f76ae68-02d0-445e-8d25-21e54f2c307c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f76ae68-02d0-445e-8d25-21e54f2c307c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a34b75d-cc18-4942-94b6-635abfbb528a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a34b75d-cc18-4942-94b6-635abfbb528a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a34b75d-cc18-4942-94b6-635abfbb528a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 9000,\n  \"fields\": [\n    {\n      \"column\": \"1478191030.045114\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2949.9364820057085,\n        \"min\": 1478191030.441377,\n        \"max\": 1478201208.580565,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          1478192262.661659,\n          1478191886.996061,\n          1478192943.126001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0316\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"018f\",\n          \"04b1\",\n          \"0316\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"05\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"22\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 69,\n        \"samples\": [\n          \"58\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"68\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 70,\n        \"samples\": [\n          \"8d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"09\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"0a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"22.1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 120,\n        \"samples\": [\n          \"0d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"20\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 161,\n        \"samples\": [\n          \"1d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"00\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 253,\n        \"samples\": [\n          \"d4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"R\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o arquivo para examinar os dados\n",
        "file_path = \"/content/rpm_df_proporcional_ajustado.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Verificar as primeiras linhas do dataset para compreender sua estrutura\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear as colunas para melhor compreensão\n",
        "data.columns = ['Timestamp', 'CAN_ID', 'DLC', 'DATA_0', 'DATA_1', 'DATA_2',\n",
        "                'DATA_3', 'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7', 'Flag']\n",
        "\n",
        "# Verificar se existem valores ausentes\n",
        "missing_data = data.isnull().sum()\n",
        "\n",
        "# Analisar a proporção de flags 'T' e 'R'\n",
        "flag_distribution = data['Flag'].value_counts(normalize=True)\n",
        "\n",
        "# Examinar estatísticas descritivas para colunas numéricas\n",
        "numeric_stats = data.describe()\n",
        "\n",
        "missing_data, flag_distribution, numeric_stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3FqQEfybDu3",
        "outputId": "0f4b5c5e-6236-44e2-81a8-a632858e3ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp    0\n",
              " CAN_ID       0\n",
              " DLC          0\n",
              " DATA_0       0\n",
              " DATA_1       0\n",
              " DATA_2       0\n",
              " DATA_3       0\n",
              " DATA_4       0\n",
              " DATA_5       0\n",
              " DATA_6       0\n",
              " DATA_7       0\n",
              " Flag         0\n",
              " dtype: int64,\n",
              " Flag\n",
              " R    0.555556\n",
              " T    0.444444\n",
              " Name: proportion, dtype: float64,\n",
              "           Timestamp     DLC\n",
              " count  9.000000e+03  9000.0\n",
              " mean   1.478193e+09     8.0\n",
              " std    2.949936e+03     0.0\n",
              " min    1.478191e+09     8.0\n",
              " 25%    1.478192e+09     8.0\n",
              " 50%    1.478192e+09     8.0\n",
              " 75%    1.478193e+09     8.0\n",
              " max    1.478201e+09     8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter o Timestamp para um formato de data legível para análise temporal\n",
        "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s')\n",
        "\n",
        "# Criar uma nova coluna para armazenar apenas a hora das mensagens\n",
        "data['Hour'] = data['Timestamp'].dt.hour\n",
        "\n",
        "# Contar o número de mensagens por hora\n",
        "messages_per_hour = data.groupby('Hour').size()\n",
        "\n",
        "# Identificar quais CAN_IDs são mais frequentes\n",
        "can_id_distribution = data['CAN_ID'].value_counts().head(10)\n",
        "\n",
        "messages_per_hour, can_id_distribution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0bTd8Q3bFuU",
        "outputId": "6fc120ae-6fb1-4cff-ea51-b4696ffe36d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Hour\n",
              " 16    5407\n",
              " 17    2510\n",
              " 19    1083\n",
              " dtype: int64,\n",
              " CAN_ID\n",
              " 0316    4293\n",
              " 043f     307\n",
              " 0153     292\n",
              " 0350     282\n",
              " 018f     279\n",
              " 0260     273\n",
              " 0130     272\n",
              " 0002     271\n",
              " 0440     265\n",
              " 0131     264\n",
              " Name: count, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição dos CAN_IDs em relação às flags 'T' e 'R'\n",
        "can_id_flag_distribution = data.groupby(['CAN_ID', 'Flag']).size().unstack(fill_value=0)\n",
        "\n",
        "# Explorar padrões nos campos 'DATA_X' para mensagens com flag 'T'\n",
        "data_injected = data[data['Flag'] == 'T']\n",
        "data_normal = data[data['Flag'] == 'R']\n",
        "\n",
        "# Calcular estatísticas descritivas para os campos 'DATA_X' para cada tipo de flag\n",
        "data_injected_stats = data_injected[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                     'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].describe()\n",
        "\n",
        "data_normal_stats = data_normal[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                 'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].describe()\n",
        "\n",
        "can_id_flag_distribution, data_injected_stats, data_normal_stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIg3F0ckbH5R",
        "outputId": "88232948-1134-43f4-a2da-c9e34df52b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Flag      R     T\n",
              " CAN_ID           \n",
              " 0002    271     0\n",
              " 00a0     25     0\n",
              " 00a1     22     0\n",
              " 0130    272     0\n",
              " 0131    264     0\n",
              " 0140    234     0\n",
              " 0153    292     0\n",
              " 018f    279     0\n",
              " 01f1    158     0\n",
              " 0260    273     0\n",
              " 02a0    258     0\n",
              " 02c0    259     0\n",
              " 0316    293  4000\n",
              " 0329    260     0\n",
              " 0350    282     0\n",
              " 0370    258     0\n",
              " 0430    123     0\n",
              " 043f    307     0\n",
              " 0440    265     0\n",
              " 04b1    171     0\n",
              " 04f0    144     0\n",
              " 0545    262     0\n",
              " 05a0      3     0\n",
              " 05a2      3     0\n",
              " 0690     22     0,\n",
              "        DATA_0 DATA_1 DATA_2 DATA_3 DATA_4 DATA_5 DATA_6 DATA_7\n",
              " count    4000   4000   4000   4000   4000   4000   4000   4000\n",
              " unique      1      1      1      1      1      1      1      1\n",
              " top        45     29     24     ff     29     24     00     ff\n",
              " freq     4000   4000   4000   4000   4000   4000   4000   4000,\n",
              "        DATA_0 DATA_1 DATA_2 DATA_3 DATA_4 DATA_5 DATA_6 DATA_7\n",
              " count    5000   5000   5000   5000   5000   5000   5000   5000\n",
              " unique     69     68     70     26    120    161     60    253\n",
              " top        00     00     00     00     00     00     00     00\n",
              " freq     1881   2099   2972   2301   2253   1604   2737   2688)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a distribuição temporal das mensagens com CAN_ID '0000' (flag 'T')\n",
        "injected_id_0000 = data[(data['CAN_ID'] == '0000') & (data['Flag'] == 'T')]\n",
        "\n",
        "# Contagem de mensagens injetadas por minuto\n",
        "injected_id_0000['Minute'] = injected_id_0000['Timestamp'].dt.minute\n",
        "injected_per_minute = injected_id_0000.groupby('Minute').size()\n",
        "\n",
        "# Explorar CAN_IDs que aparecem menos frequentemente para identificar possíveis outliers\n",
        "rare_can_ids = data['CAN_ID'].value_counts().tail(10)\n",
        "\n",
        "# Verificar se existem correlações entre os campos 'DATA_X' para as mensagens normais\n",
        "data_normal_numeric = data_normal[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                                   'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].apply(lambda x: x.apply(int, base=16))\n",
        "correlation_matrix = data_normal_numeric.corr()\n",
        "\n",
        "injected_per_minute, rare_can_ids, correlation_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TujNMr8mbKVR",
        "outputId": "2b15af41-720f-4440-ae51-6c60f1d4bea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Series([], dtype: int64),\n",
              " CAN_ID\n",
              " 0140    234\n",
              " 04b1    171\n",
              " 01f1    158\n",
              " 04f0    144\n",
              " 0430    123\n",
              " 00a0     25\n",
              " 0690     22\n",
              " 00a1     22\n",
              " 05a2      3\n",
              " 05a0      3\n",
              " Name: count, dtype: int64,\n",
              "           DATA_0    DATA_1    DATA_2    DATA_3    DATA_4    DATA_5    DATA_6  \\\n",
              " DATA_0  1.000000  0.177508 -0.170279 -0.203931  0.164053  0.068461 -0.139653   \n",
              " DATA_1  0.177508  1.000000  0.211097  0.196646 -0.079955  0.216130 -0.256579   \n",
              " DATA_2 -0.170279  0.211097  1.000000  0.101969  0.273647 -0.112295  0.230215   \n",
              " DATA_3 -0.203931  0.196646  0.101969  1.000000  0.051195  0.603532 -0.027500   \n",
              " DATA_4  0.164053 -0.079955  0.273647  0.051195  1.000000  0.350871  0.324620   \n",
              " DATA_5  0.068461  0.216130 -0.112295  0.603532  0.350871  1.000000  0.015282   \n",
              " DATA_6 -0.139653 -0.256579  0.230215 -0.027500  0.324620  0.015282  1.000000   \n",
              " DATA_7 -0.230719  0.142951  0.114902 -0.041642 -0.038283 -0.107408 -0.114770   \n",
              " \n",
              "           DATA_7  \n",
              " DATA_0 -0.230719  \n",
              " DATA_1  0.142951  \n",
              " DATA_2  0.114902  \n",
              " DATA_3 -0.041642  \n",
              " DATA_4 -0.038283  \n",
              " DATA_5 -0.107408  \n",
              " DATA_6 -0.114770  \n",
              " DATA_7  1.000000  )"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter os campos 'DATA_X' para valores numéricos para análise de correlação\n",
        "data_numeric = data[['DATA_0', 'DATA_1', 'DATA_2', 'DATA_3',\n",
        "                     'DATA_4', 'DATA_5', 'DATA_6', 'DATA_7']].apply(lambda x: x.apply(int, base=16))\n",
        "\n",
        "# Adicionar a flag como numérica (T = 1, R = 0) para facilitar a análise\n",
        "data_numeric['Flag'] = data['Flag'].apply(lambda x: 1 if x == 'T' else 0)\n",
        "\n",
        "# Calcular a correlação entre os campos de dados e a flag\n",
        "correlation_with_flag = data_numeric.corr()['Flag'].drop('Flag')\n",
        "\n",
        "correlation_with_flag\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "uvkaERJkbOoU",
        "outputId": "c5160152-af9f-4b94-ca8c-8ca7fce8ff76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DATA_0    0.073895\n",
              "DATA_1   -0.025401\n",
              "DATA_2   -0.001812\n",
              "DATA_3    0.795754\n",
              "DATA_4   -0.130245\n",
              "DATA_5   -0.260580\n",
              "DATA_6   -0.291076\n",
              "DATA_7    0.897767\n",
              "Name: Flag, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DATA_0</th>\n",
              "      <td>0.073895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_1</th>\n",
              "      <td>-0.025401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_2</th>\n",
              "      <td>-0.001812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_3</th>\n",
              "      <td>0.795754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_4</th>\n",
              "      <td>-0.130245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_5</th>\n",
              "      <td>-0.260580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_6</th>\n",
              "      <td>-0.291076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATA_7</th>\n",
              "      <td>0.897767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando o modelo de Regressão Logística\n",
        "model_minmax = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    solver='lbfgs',\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Treinando o modelo com os dados de treino\n",
        "model_minmax.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliando no conjunto de treino\n",
        "y_train_pred = model_minmax.predict(X_train_scaled)\n",
        "y_train_prob = model_minmax.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics(y_train, y_train_pred, y_train_prob, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliando no conjunto de teste\n",
        "y_test_pred = model_minmax.predict(X_test_scaled)\n",
        "y_test_prob = model_minmax.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics(y_test, y_test_pred, y_test_prob, \"Teste\")\n",
        "\n",
        "# Avaliando no conjunto de validação\n",
        "y_val_pred = model_minmax.predict(X_val_scaled)\n",
        "y_val_prob = model_minmax.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics(y_val, y_val_pred, y_val_prob, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmfDTUTpbR0D",
        "outputId": "76863530-2701-4659-9006-050392898acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 0.9996\n",
            "Precisão: 0.9992\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9996\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2968    2]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 0.9994\n",
            "Precisão: 0.9987\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9994\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1006    1]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo Random Forest com regularização\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_rf(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_rf = model_rf.predict(X_train_scaled)\n",
        "y_train_prob_rf = model_rf.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_rf(y_train, y_train_pred_rf, y_train_prob_rf, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_rf = model_rf.predict(X_test_scaled)\n",
        "y_test_prob_rf = model_rf.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_rf(y_test, y_test_pred_rf, y_test_prob_rf, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_rf = model_rf.predict(X_val_scaled)\n",
        "y_val_prob_rf = model_rf.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_rf(y_val, y_val_pred_rf, y_val_prob_rf, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoaJ_B9_fIJy",
        "outputId": "295e679a-fab2-4f37-e574-26ed783ae6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo de Árvore de Decisão com regularização\n",
        "model_tree = DecisionTreeClassifier(\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_tree(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_tree = model_tree.predict(X_train_scaled)\n",
        "y_train_prob_tree = model_tree.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_tree(y_train, y_train_pred_tree, y_train_prob_tree, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_tree = model_tree.predict(X_test_scaled)\n",
        "y_test_prob_tree = model_tree.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_tree(y_test, y_test_pred_tree, y_test_prob_tree, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_tree = model_tree.predict(X_val_scaled)\n",
        "y_val_prob_tree = model_tree.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_tree(y_val, y_val_pred_tree, y_val_prob_tree, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYiVcoKUhBA4",
        "outputId": "c7de2dc7-f91d-4c89-d8a8-20d6081ac07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo de Gradient Boosting\n",
        "model_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_gb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_gb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_gb = model_gb.predict(X_train_scaled)\n",
        "y_train_prob_gb = model_gb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_gb(y_train, y_train_pred_gb, y_train_prob_gb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_gb = model_gb.predict(X_test_scaled)\n",
        "y_test_prob_gb = model_gb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_gb(y_test, y_test_pred_gb, y_test_prob_gb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_gb = model_gb.predict(X_val_scaled)\n",
        "y_val_prob_gb = model_gb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_gb(y_val, y_val_pred_gb, y_val_prob_gb, \"Validação\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvBtNbmBiJ-P",
        "outputId": "3ced7394-1157-441d-e9cb-604fbb03dc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo K-Nearest Neighbors\n",
        "model_knn = KNeighborsClassifier(\n",
        "    n_neighbors=5,\n",
        "    weights='uniform',\n",
        "    metric='minkowski',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_knn(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_knn = model_knn.predict(X_train_scaled)\n",
        "y_train_prob_knn = model_knn.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_knn(y_train, y_train_pred_knn, y_train_prob_knn, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_knn = model_knn.predict(X_test_scaled)\n",
        "y_test_prob_knn = model_knn.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_knn(y_test, y_test_pred_knn, y_test_prob_knn, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_knn = model_knn.predict(X_val_scaled)\n",
        "y_val_prob_knn = model_knn.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_knn(y_val, y_val_pred_knn, y_val_prob_knn, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5UYQDmmjRQR",
        "outputId": "211fe9bb-194a-4f35-9cef-2625f09130c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo SVM\n",
        "model_svm = SVC(\n",
        "    kernel='rbf',\n",
        "    C=1.0,\n",
        "    probability=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_svm(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_svm = model_svm.predict(X_train_scaled)\n",
        "y_train_prob_svm = model_svm.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_svm(y_train, y_train_pred_svm, y_train_prob_svm, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_svm = model_svm.predict(X_test_scaled)\n",
        "y_test_prob_svm = model_svm.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_svm(y_test, y_test_pred_svm, y_test_prob_svm, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_svm = model_svm.predict(X_val_scaled)\n",
        "y_val_prob_svm = model_svm.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_svm(y_val, y_val_pred_svm, y_val_prob_svm, \"Validação\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwUOkVFDmFkE",
        "outputId": "e821526b-d8a4-47dc-99ac-7183dd82398d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo XGBoost\n",
        "model_xgb = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=10,\n",
        "    min_child_weight=1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_xgb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_xgb = model_xgb.predict(X_train_scaled)\n",
        "y_train_prob_xgb = model_xgb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_xgb(y_train, y_train_pred_xgb, y_train_prob_xgb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_xgb = model_xgb.predict(X_test_scaled)\n",
        "y_test_prob_xgb = model_xgb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_xgb(y_test, y_test_pred_xgb, y_test_prob_xgb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_xgb = model_xgb.predict(X_val_scaled)\n",
        "y_val_prob_xgb = model_xgb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_xgb(y_val, y_val_pred_xgb, y_val_prob_xgb, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNokTQ1DowJW",
        "outputId": "78062a48-7834-496d-bde4-c06f69ab04b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [16:51:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score, f1_score\n",
        ")\n",
        "\n",
        "# Supondo que 'data_numeric' esteja carregado corretamente\n",
        "X = data_numeric.drop('Flag', axis=1)\n",
        "y = data_numeric['Flag']\n",
        "\n",
        "# Dividindo os dados em treino (60%), validação (20%) e teste (20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Aplicando o MinMaxScaler nos conjuntos de treino, validação e teste\n",
        "scaler_minmax = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_minmax.fit_transform(X_train)\n",
        "X_val_scaled = scaler_minmax.transform(X_val)\n",
        "X_test_scaled = scaler_minmax.transform(X_test)\n",
        "\n",
        "# Criando e treinando o modelo CatBoost\n",
        "model_cb = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    learning_rate=0.1,\n",
        "    depth=10,\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "model_cb.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Função para calcular e exibir métricas\n",
        "def print_metrics_cb(y_true, y_pred, y_prob, dataset_name):\n",
        "    print(f\"\\nMétricas para o conjunto de {dataset_name}:\")\n",
        "    print(f\"Acurácia: {accuracy_score(y_true, y_pred):.4f}\")\n",
        "    print(f\"Precisão: {precision_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"F1-Score: {f1_score(y_true, y_pred, pos_label=1):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_true, y_prob):.4f}\")\n",
        "    print(\"\\nMatriz de Confusão:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de treino\n",
        "y_train_pred_cb = model_cb.predict(X_train_scaled)\n",
        "y_train_prob_cb = model_cb.predict_proba(X_train_scaled)[:, 1]\n",
        "print_metrics_cb(y_train, y_train_pred_cb, y_train_prob_cb, \"Treino\")\n",
        "\n",
        "\n",
        "# Avaliar no conjunto de teste\n",
        "y_test_pred_cb = model_cb.predict(X_test_scaled)\n",
        "y_test_prob_cb = model_cb.predict_proba(X_test_scaled)[:, 1]\n",
        "print_metrics_cb(y_test, y_test_pred_cb, y_test_prob_cb, \"Teste\")\n",
        "\n",
        "# Avaliar no conjunto de validação\n",
        "y_val_pred_cb = model_cb.predict(X_val_scaled)\n",
        "y_val_prob_cb = model_cb.predict_proba(X_val_scaled)[:, 1]\n",
        "print_metrics_cb(y_val, y_val_pred_cb, y_val_prob_cb, \"Validação\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1bcOURixBnV",
        "outputId": "ee806643-55f1-46d5-a1ad-fc6a182650a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Métricas para o conjunto de Treino:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[2970    0]\n",
            " [   0 2430]]\n",
            "\n",
            "Métricas para o conjunto de Teste:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1007    0]\n",
            " [   0  793]]\n",
            "\n",
            "Métricas para o conjunto de Validação:\n",
            "Acurácia: 1.0000\n",
            "Precisão: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Matriz de Confusão:\n",
            "[[1023    0]\n",
            " [   0  777]]\n"
          ]
        }
      ]
    }
  ]
}